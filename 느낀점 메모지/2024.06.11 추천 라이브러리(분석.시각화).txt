2024.06.11

이론적 근거

왜 이 모델을 사용했는가?(근거)

================================================

시각화 하기 좋은 라이브러리
1. Matplotlib
2. Seaborn
3. Plotly
4. TensorBoard
5. Altair

================================================

1. Matplotlib
장점 
- 기본적이고 강력
- 커스터마이징 가능 : 그래프의 거의 모든 요소들 커스터마이징 가능 
-  광범위한 지원 : 커뮤니티에서 널리 사용되고 있으며, 많은 자료와 예제
단점
- 복잡함
- 인터랙티브 기능 제한 : 정적인 이미지 파일로 시각화되며, 기능이 제한적

2. Seaborn
장점
- Matplotlib 기반 : 기능을 그대로 사용 가능
- 고수준 API : 간단한 함수 호출로 복잡한 시각화 생성
- 데이터프레임 통합 : 데이터 분석과 시각화가 쉬움
단점
- Matplotlib 의존성
- 인터랙티브 기능 부족

3. Plotly
장점
- 인터랙티브 시각화
- 웹 기반 통합 : 웹 애플리케이션과 쉽게 통합할 수 있어 대화형 보고서 작성에 유용
- 다양한 차트 타입 : 3D 그래프. 지리적 시각화 등 다양한 차트를 지원
단점
- 학습 곡선
- 성능 : 대규모 데이터셋을 다룰 때 성능 문제가 발생

4. TensorBoard
장점
- 실시간 시각화 : 학습 중인 모델을 실시간으로 모니터링
- TensorFlow 통합 : TensorFlow와 완벽하게 통합
- 다양한 플러그인 : 히스토그램, 이미지, 그래프 구조 등 다양한 플러그인을 통해 시각화
단점
- TensorFlow 전용
- 설정 필요

5. Altair
장점
- 선언적 시각화 : 간단하고 직관적인 API를 통해 복잡한 시각화 쉽게 생성
- 인터랙티브 기능
- Vega-Lite 기반 : Json 형식의 스펙을 사용하여 시각화를 정의
단점
- 복잡한 시각화 제한 
- 성능 : 대규모 데이터셋 처리하는데 성능 문제 발생
- 지원 부족 : 다른 라이브러리에 비해 덜 사용 , 자료나 커뮤니티 지원 부족

===========================================================================================

=> 5가지의 라이브러리를 가지고 GPT에게 프로경기 머신러닝 모델 학습 시킨 거 시각화 시킬 때 적합한 라이브러리 추천 이유 설명 검색

1.Plotly ( 가장 추천 )
이유
- 인터랙티브 시각화 : 경기 데이터는 복잡하고 다차원적일 수 이있다
데이터 탐색을 보다 직관적으로 할 수 있게 한다
-> 예를 들어서 경기 내의 다양한 변수 ( 챔피언 선택, 아이템빌드, 킬/데스)를 한 그래프에서 분석가능

- 대시보드 생성 : 웹 기반 대시보드를 쉽게 만들 수 있어, 모델 성능을 모니터링하거나 결과를 공유하는데 유용

- 다양한 차트 타입 지원 : 시간에 따른 변수 변화, 팀 간의 비교, 히트맵 등을 포함한 다양한 시각화를 제공

============================================================================================
덜 추천되는 이유
Matplotblib
- 정적 시각화 : 인터랙티브 기능이 제한
- 복잡성 : 많은 코드와 설정이 필요
- 스타일 :  기본 스타일이 단순, 세련된 그래프를 만들기 위해서는 추가적인 설정 필요

Seaborn
- Matplotblib 기반
- 고수준 API
- 정적 시각화 : 동적 데이터 탐색에 덜 적합

TensorBoard
- TensorFlow전용 
- 학습 모니터닝 : 모델 학습 과정의 모니터링에는 유용, 일반적인 데이터 시각화에는 기능 제한

Altair
- 제한된 복잡성 : 선언적 시각화 언어를 사용하여 간단하고 직관적, 복잡한 시각화 구현 제약
- 성능 : 데이터셋을 처리할 때 성능 저하
- 지원 부족 : 다른 라이브러리에 비해 자료나 지원 부족

============================================================================================

데이터 분석에 유용한 라이브러리
1. Pandas
2. Numpy
3. SciPy
4. Scikit-learn
5. Statsmodels
6. Dask

============================================================================================
GPT 추천 라이브러리와 다른 라이브러리가 덜 추천되는 이유
1. Pandas
- 데이터프레임을 사용하여 구조화된 데이터를 효율적으로 조작 분석
- 데이터 필털이, 그룹화, 집계 등의 기능을 통해 복잡한 LoL 데이터 쉽게 다룰 수 있다
- CSV, Excel, SQL 등 다양한 데이터 소스에서 데이터를 읽고 쓰기 가능
2. Scikit-learn
- 데이터 전처리 기능이 강력, 범주형 변수 인코딩, 스케일링, 결측값 처리 등을 쉽게 수행
- 다양한 머신러닝 알고리즘을 제공하여 예측 모델을 구추갛고 평가
- 모델 평가 및 교차 검증 기능을 통해 모델의 성능을 정확하게 측정
=============================================================================================
덜 추천 이유
Numpy
- 주로 수치 계산과 다차원 배열 조작에 최적화
- 데이터 조작 기능이 Pandas보다 제한적, 고수준의 데이터 분석 기능 제공 X
- 데이터를 구조화하고 분석하는 데 있어 Pandas만큼 직관적 X

SciPy
- 과학적 계산, 최적화, 선형대수 등의 기능을 강점
- 통계적 분석이나 수학적 연산에는 유용하지만, 데이터 조작 및 기본적인 데이터 분석에는 덜 적합
- 머신러닝 모델 구구 및 평가 기능 제한적

Statsmodels
- 통계 모델링과 계량 경제학에 사용
- 회귀 분석, 시계적 분석 등 통계적 분석에는 강력하지만, 범용적인 머신런이 알고리즘 지원 부족

Dask
- 대용량 데이터를 처리하는 데 최적화 , 병렬 연산 지원
- 데이터셋이 매우 크지 않은 경우, 병렬 처리 기능은 과도

============================================================================================

XGBOOST
- ( eXtreame Gradient Boosting ) 
- 그래디언트 부스팅 알고리즘의 확장 버전
- 뛰어난 성능과 속도
- 다양한 기능
- 즐겨 사용하는 머신 러닝 라이브러리

하이퍼파라미터 튜닝 : 성능을 최적화하는데 중요한 역할
Grid Search / Random Search 를 사용하여 수행
그리드 서치 : 지정된 하이퍼파라미터 값들의 모든 조합을 시도
랜덤 서치 : 지정된 하이퍼파라미터 값 범위 내에서 무작위로 조합 시도

실험 결과 (1000개의 데이터로)
확실히 랜덤 서치는 시간이 엄청 짧다
그리드 서치는 굉장히 오래 걸려서 감이 안온다 
CV를 줄이면 시간이 단축되는데 CV=3으로 조절했음에도 너무 오래 걸린다
GPU가 있으면 확실히 시간이 줄어들 것 같다
그리드 서치는 모든 변수에 대한 조합을 전부 다 학습하기 때문에 
변수가 많냐 적냐도 시간에 영향을 줄 것 같다
내가 현재까지 알기로는 변수는 4~5개 정도 되는 것으로 알고 있다
하이퍼 파라미터 개선점은 계속해서 공부해야 봐야할 것 같다

에포크 보면서 수치 확 오르거나 떨어지는 구간 
max_depth 수치 건들어보면서 확인
조기 종료

============================================================================================

공부하면서 알게 된 내용

axis = 1 ( 데이터 프레임에서 열(axis=1)을 기준으로 연산을 수행

